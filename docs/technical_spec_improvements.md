# Техническое задание: расширение функциональности системы TRIZ‑анализа

## Общая цель

Настоящая итерация разработки предполагает расширение возможностей созданной системы
для анализа патентных формул, включая поддержку различных моделей генеративного ИИ,
интеграцию функций улучшения формулы в пользовательские интерфейсы, а также
разработку набора автоматических тестов для валидации корректности работы.

## Требования к реализации

### 1. Поддержка альтернативных LLM

* **Модуль LLM Prompt Enhancer** должен быть способен использовать разные
  языковые модели в зависимости от доступности API.  Помимо OpenAI,
  необходимо предусмотреть следующие интеграции:
  - **Anthropic Claude** – добавьте возможность задавать эндпойнт и токен
    через параметры функции `enhance_formula()` или переменные окружения;
  - **Mistral** (или другие open‑source модели) – при наличии локальной
    установки модель должна вызываться через обёртку, обеспечивающую
    совместимый интерфейс (входной prompt, выходной JSON);
  - **Azure OpenAI** – используйте параметры `api_base` и `api_version`
    для настройки клиента.  Все ключи и параметры конфигурации должны
    передаваться через аргументы функции или переменные окружения;
  - Интеграции должны быть организованы так, чтобы новая модель
    подключалась без изменений существующего кода.  Предусмотрите
    регистрацию доступных провайдеров и выбор по имени.
* В случае отсутствия подключения к внешним сервисам функция должна
  продолжать работать по эвристическому сценарию.

### 2. Подключение к интерфейсам

* **Streamlit‑приложение**:
  - Расширьте `streamlit_app.py`: добавьте кнопку «Улучшить формулу»,
    которая вызывает `generate_formula()` и `enhance_formula()` для
    введённого описания, а затем отображает улучшенное название,
    предложения по неочевидности и патентное обоснование.
  - Предусмотрите возможность скачивания отчёта с улучшенной формулой и
    рекомендациями в формате `.docx` через существующую функцию
    `export_report()`.
* **CLI‑команда**:
  - В `cli.py` добавьте флаг `--enhance` (или отдельную подкоманду),
    который запускает генерацию формулы и её последующее улучшение.
    Результаты должны выводиться в консоль и, по запросу пользователя,
    экспортироваться в файл.
  - При вызове без `--enhance` поведение должно оставаться прежним.

### 3. Тесты и валидация

* Разработать набор unit‑тестов для функции `generate_formula()` и
  связанного модуля `prompt_enhancer.py`:
  - Создать тесты для коротких, длинных и средних описаний, чтобы
    убедиться в корректности извлечения признаков и формировании формул.
  - Проверить, что `enhance_formula()` корректно обрабатывает формулы
    без отличительных признаков и с несколькими признаками.
  - При наличии подключённого LLM‑провайдера тесты должны проверять
    структуру JSON‑ответа и наличие ключевых полей.
* Применять тестовый фреймворк `pytest`.  Тесты должны запускаться
  автоматически командой `pytest` в корне проекта.
* Включить тесты в CI/CD (если предусмотрено) и обеспечить генерацию
  отчёта о покрытии кода.

## Дополнительные рекомендации

* Соблюдать принципы модульности: изменения в одном компоненте не
  должны нарушать работу других.  Все новые зависимости должны быть
  обернуты так, чтобы основная логика продолжала работать при их
  отсутствии.
* В тестовых описаниях избегать слишком общих формулировок; наполняйте
  примеры конкретными техническими терминами и эффектами, основываясь
  на рекомендации сохранять только **специфические и применимые
  предпочтения**【340773968921043†L63-L69】 и игнорировать банальные
  высказывания【340773968921043†L19-L27】.  Это повысит надёжность
  тестов и полезность обратной связи от LLM.
* Документировать все новые функции и аргументы, добавляя примеры
  использования и описания форматов входа/выхода.  Это облегчит
  интеграцию системы в другие сервисы.